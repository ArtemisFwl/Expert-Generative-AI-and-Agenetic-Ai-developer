{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas seaborn matplotlib gradio ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Titanic Dataset\n",
    "url = r\"D:\\GenAI\\Expert-Generative-AI-and-Agenetic-Ai-developer\\eda-integration-llm-titanic-data\\titanic_ dataset_final.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "# Display dataset info\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing Values Check\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Survival Rate Visualization\n",
    "plt.figure(figsize=(3, 2))   # width, height in inches\n",
    "sns.countplot(x='Survived', data=df, width=0.2)\n",
    "plt.title(\"Survival Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\n",
      "Collecting pydantic>=2.9\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (4.12.1)\n",
      "Requirement already satisfied: certifi in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (2026.1.4)\n",
      "Requirement already satisfied: idna in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (3.11)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.41.5\n",
      "  Using cached pydantic_core-2.41.5-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Installing collected packages: typing-inspection, pydantic-core, annotated-types, pydantic, ollama\n",
      "Successfully installed annotated-types-0.7.0 ollama-0.6.1 pydantic-2.12.5 pydantic-core-2.41.5 typing-inspection-0.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ollama imported successfully\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "print(\"‚úÖ ollama imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç AI Generated Insights:\n",
      "\n",
      "Here's the analysis of the dataset summary:\n",
      "\n",
      "**Key Insights:**\n",
      "\n",
      "*   **Mean:** The mean of the passenger ID values is 446.000000, which is 446.000000. This suggests that the passenger ID values represent a relatively uniform distribution across the dataset.\n",
      "*   **Standard Deviation:** The standard deviation of the passenger ID values is 0.806057. This indicates that the passenger ID values are relatively spread across the dataset.\n",
      "*   **Minimum:** The minimum passenger ID value is 0.000000. This suggests that the passenger ID values are relatively low, suggesting that the dataset may be relatively small.\n",
      "*   **Maximum:** The maximum passenger ID value is 1.000000. This indicates that the passenger ID values are relatively high, suggesting that the dataset may be relatively large.\n",
      "*   **Median:** The median of the passenger ID values is 0.000000. This indicates that the passenger ID values are relatively evenly distributed across the dataset.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "The dataset summary indicates that the passenger ID values are relatively uniform across the dataset. The mean is 446.000000, which suggests a relatively uniform distribution. The standard deviation is 0.806057, which indicates a relatively spread across the dataset. The minimum is 0.000000, suggesting a relatively low value. The maximum is 1.000000, suggesting a relatively high value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_insights(df_summary):\n",
    "    prompt = f\"\"\"\n",
    "Analyze the following Titanic dataset summary\n",
    "and provide key insights in bullet points:\n",
    "\n",
    "{df_summary}\n",
    "\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=\"gemma3:270m\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "summary = df.describe().to_string()\n",
    "insights = generate_insights(summary)\n",
    "\n",
    "print(\"\\nüîç AI Generated Insights:\\n\")\n",
    "print(insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Using cached gradio-6.2.0-py3-none-any.whl (23.0 MB)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (12.1.0)\n",
      "Collecting uvicorn>=0.14.0\n",
      "  Using cached uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2\n",
      "  Using cached fastapi-0.128.0-py3-none-any.whl (103 kB)\n",
      "Collecting semantic-version~=2.0\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (3.0.3)\n",
      "Collecting aiofiles<25.0,>=22.0\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (6.0.3)\n",
      "Collecting huggingface-hub<2.0,>=0.33.5\n",
      "  Using cached huggingface_hub-1.2.4-py3-none-any.whl (520 kB)\n",
      "Requirement already satisfied: packaging in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: jinja2<4.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Collecting brotli>=1.1.0\n",
      "  Using cached brotli-1.2.0-cp310-cp310-win_amd64.whl (369 kB)\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (2.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (4.15.0)\n",
      "Collecting gradio-client==2.0.2\n",
      "  Using cached gradio_client-2.0.2-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (4.12.1)\n",
      "Collecting groovy~=0.1\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from gradio) (2.2.6)\n",
      "Collecting orjson~=3.0\n",
      "  Using cached orjson-3.11.5-cp310-cp310-win_amd64.whl (133 kB)\n",
      "Collecting python-multipart>=0.0.18\n",
      "  Using cached python_multipart-0.0.21-py3-none-any.whl (24 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.7\n",
      "  Using cached safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
      "Collecting typer<1.0,>=0.12\n",
      "  Using cached typer-0.21.1-py3-none-any.whl (47 kB)\n",
      "Collecting starlette<1.0,>=0.40.0\n",
      "  Using cached starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Collecting ffmpy\n",
      "  Using cached ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Collecting annotated-doc>=0.0.2\n",
      "  Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: certifi in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "Collecting typer-slim\n",
      "  Using cached typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.20.2-py3-none-any.whl (16 kB)\n",
      "Collecting shellingham\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting tqdm>=4.42.1\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (0.4.2)\n",
      "Collecting click>=8.0.0\n",
      "  Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: colorama in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\genai\\expert-generative-ai-and-agenetic-ai-developer\\eda-integration-llm-titanic-data\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, brotli, tqdm, tomlkit, shellingham, semantic-version, python-multipart, orjson, mdurl, hf-xet, groovy, fsspec, filelock, ffmpy, click, annotated-doc, aiofiles, uvicorn, typer-slim, markdown-it-py, starlette, rich, typer, safehttpx, huggingface-hub, fastapi, gradio-client, gradio\n",
      "Successfully installed aiofiles-24.1.0 annotated-doc-0.0.4 brotli-1.2.0 click-8.3.1 fastapi-0.128.0 ffmpy-1.0.0 filelock-3.20.2 fsspec-2025.12.0 gradio-6.2.0 gradio-client-2.0.2 groovy-0.1.2 hf-xet-1.2.0 huggingface-hub-1.2.4 markdown-it-py-4.0.0 mdurl-0.1.2 orjson-3.11.5 pydub-0.25.1 python-multipart-0.0.21 rich-14.2.0 safehttpx-0.1.7 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.50.0 tomlkit-0.13.3 tqdm-4.67.1 typer-0.21.1 typer-slim-0.21.1 uvicorn-0.40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ gradio imported\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "print(\"‚úÖ gradio imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://dcb883403f746e2cf8.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://dcb883403f746e2cf8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def eda_analysis(file):\n",
    "    df = pd.read_csv(file.name)\n",
    "    summary = df.describe().to_string()\n",
    "    insights = generate_insights(summary)\n",
    "    return insights\n",
    "\n",
    "# Create Web Interface\n",
    "demo = gr.Interface(fn=eda_analysis, inputs=\"file\", outputs=\"text\", title=\"AI-Powered EDA with Mistral\")\n",
    "\n",
    "# Launch App\n",
    "demo.launch(share=True)  # Use share=True for Google Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
